{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pybrain\n",
    "from pybrain.structure import FeedForwardNetwork\n",
    "from pybrain.structure import LinearLayer, SigmoidLayer\n",
    "from pybrain.structure import FullConnection\n",
    "from pybrain.datasets import SupervisedDataSet\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import random\n",
    "import ast\n",
    "import time\n",
    "import sqlalchemy\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy import event\n",
    "import sqlite3\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import *\n",
    "import urllib2\n",
    "import urllib\n",
    "import json\n",
    "import glob\n",
    "import pprint\n",
    "import dateutil.parser\n",
    "import pprint\n",
    "import re\n",
    "from sklearn import linear_model, datasets\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from sklearn import svm\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "import numpy\n",
    "import time\n",
    "import sqlalchemy\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy import event\n",
    "from sqlalchemy.dialects.mysql import LONGTEXT\n",
    "import sqlite3\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import *\n",
    "import urllib2\n",
    "import urllib\n",
    "import json\n",
    "import pprint\n",
    "import dateutil.parser\n",
    "import gevent\n",
    "import datetime\n",
    "import marshal\n",
    "\n",
    "import re, math, collections, itertools\n",
    "import nltk, nltk.classify.util, nltk.metrics\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import scrapy\n",
    "\n",
    "import urllib3.contrib.pyopenssl\n",
    "urllib3.contrib.pyopenssl.inject_into_urllib3()\n",
    "\n",
    "import requests\n",
    "from scrapy.http import TextResponse\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible Strategies:\n",
    "\n",
    "If all linked contracts are priced in total above $1, buy \"no\" for all and hold until end (or until they balance). Problem is that you'll be holding possibly a long time (tying up assets).\n",
    "\n",
    "Spread trading. Risks: price movement leaves you with less valuable shares. \n",
    "\n",
    "Buy all the shares reliably at 9x cents or above, assuming that these pretty much always come true. Risks: don't know if this is true.\n",
    "\n",
    "Try actually learning about the market/trading on news data/etc/etc.\n",
    "\n",
    "Market manipulation\n",
    "\n",
    "MAKING AN OFFER DOESN\"T DEDUCT FROM YOUR BALANCE. okay maybe this isn't actually true. Lots of cheesing and legitimate strategies can come of this.\n",
    "Ex. make buy offers with 1 cent in account to make it look like there's a great arbitrage opportunity (so someone buys something you want to sell), or so prices look really high. Ex. I have a bunch of shares of something I bought at .3. I put up a buy order for .5, and hope that other buyers raise their offers also. Then, I sell to those buyers.\n",
    "\n",
    "Buy out a lot of shares, then re-list them higher. \n",
    "\n",
    "Imagine something is trading for .4-.6. If I put up a buy order for a yes at .41, a sell order shows up for \"no\". I can be on another account and buy this \n",
    "^ this idea is the one where you can kill any buy or sell order with a 1% loss by generating shares. then, you can artifically inflate a market to sell other shares higher, or just make money selling the now larger spread. Kind of a more advanced version of \"buy lots of shares, relist higher\".\n",
    "\n",
    "so to move a market upwards, you can just buy out all the shares and re-list them higher. you make money on selling the shares higher, and you can make money by generating some no's and selling them at the higher price also (shorting). \n",
    "\n",
    "to move a market down, you do the exact same thing from the other side. buy out all the sell orders for \"no's\", and offer to sell them (a buy order on the yes side cheaper than it was) higher. then, generate some yes's etc etc\n",
    "\n",
    "you can just walk a market up and down, and make profit the whole time - because you know where the market is going.\n",
    "\n",
    "momentum trading - jump on the bandwagons!!! look at upward vs downward pressures\n",
    "\n",
    "Short yourself?\n",
    "\n",
    "grab cheap shares that were sold to a small buy order and then left cheap because there were more shares sold than the buy order, then re-list higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sleep_time = .6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "mysql_url = \"mysql://forex:yummy4money@forex.c2ggnaqt6wye.us-west-1.rds.amazonaws.com/forex\"\n",
    "sqlite_url = 'sqlite:///database.db'\n",
    "db = create_engine(mysql_url, echo=False)\n",
    "session = sessionmaker()\n",
    "session.configure(bind=db)\n",
    "session = session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Question(Base):\n",
    "    __tablename__ = \"questions\"\n",
    "    \n",
    "    question_id = Column(Integer, primary_key = True)\n",
    "    symbol = Column(String(40))\n",
    "    \n",
    "    timestamp = Column(DateTime, primary_key = True)\n",
    "    start_date = Column(DateTime)\n",
    "    end_date = Column(DateTime)\n",
    "    \n",
    "    shares_traded = Column(Integer)\n",
    "    total_shares = Column(Integer)\n",
    "    today_volume = Column(Integer)\n",
    "    today_change = Column(Integer)\n",
    "    \n",
    "    def __init__(self, question_id, symbol, timestamp, start_date, end_date, shares_traded, total_shares, today_volume, today_change):\n",
    "        self.question_id = question_id\n",
    "        self.symbol = symbol\n",
    "        self.timestamp = timestamp\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.shares_traded = shares_traded\n",
    "        self.total_shares = total_shares\n",
    "        self.today_volume = today_volume\n",
    "        self.today_change = today_change\n",
    "\n",
    "class BidOffer(Base):\n",
    "    __tablename__ = \"bids_offers\"\n",
    "    \n",
    "    question_id = Column(Integer, primary_key = True)\n",
    "    timestamp = Column(DateTime, primary_key = True)\n",
    "    \n",
    "    price = Column(Integer, primary_key = True)\n",
    "    shares = Column(Integer)\n",
    "    \n",
    "    buy_order = Column(Boolean)\n",
    "    \n",
    "    def __init__(self, question_id, timestamp, price, shares, buy_order):\n",
    "        self.question_id = question_id\n",
    "        self.timestamp = timestamp\n",
    "        self.price = price\n",
    "        self.shares = shares\n",
    "        self.buy_order = buy_order\n",
    "\n",
    "class MarketQuestion(Base):\n",
    "    __tablename__ = \"market_questions\"\n",
    "    \n",
    "    market_question_id = Column(Integer, primary_key = True)\n",
    "    question_id = Column(Integer, primary_key = True)\n",
    "    \n",
    "    def __init__(self, market_question_id, question_id):\n",
    "        self.market_question_id = market_question_id\n",
    "        self.question_id = question_id\n",
    "        \n",
    "Base.metadata.create_all(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "pages = [\"https://www.predictit.org/Browse/Category/6/US-Elections\",\n",
    "        \"https://www.predictit.org/Browse/Category/13/US-Politics\",\n",
    "        \"https://www.predictit.org/Browse/Category/4/World\"]\n",
    "\n",
    "links = []\n",
    "\n",
    "for page in pages:\n",
    "    r = requests.get(page)\n",
    "    response = TextResponse(r.url, body=r.text, encoding='utf-8')\n",
    "    relative_links = response.xpath('//div[@id=\"marketList\"]/div/div/div/a/@href').extract()\n",
    "    absolute_links = [\"https://www.predictit.org\" + x for x in relative_links]\n",
    "    links += absolute_links\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "market_links = []\n",
    "contract_links = []\n",
    "\n",
    "for link in links:\n",
    "    if \"/Market/\" in link:\n",
    "        market_links.append(link)\n",
    "    elif \"/Contract/\" in link:\n",
    "        contract_links.append(link)\n",
    "    else:\n",
    "        print \"wtf\"\n",
    "    \n",
    "print len(market_links)\n",
    "print len(contract_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 924 ms, sys: 32 ms, total: 956 ms\n",
      "Wall time: 34.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "new_links = []\n",
    "\n",
    "for link in market_links:\n",
    "    id = re.search(\"/\\d+/\", link).group().strip(\"/\")\n",
    "    ajax_link = \"https://www.predictit.org/Home/GetContractListAjax?marketId=%i\" % int(id)\n",
    "    #print ajax_link\n",
    "    r = requests.get(ajax_link)\n",
    "    response = TextResponse(r.url, body=r.text, encoding='utf-8')\n",
    "    #print response.xpath(\"//div\")\n",
    "    response_links = response.xpath(\"//*[contains(concat(' ', normalize-space(@class), ' '), 'visible-xs')]//*[contains(concat(' ', normalize-space(@class), ' '), 'outcome-title')]/a/@href\").extract()\n",
    "    for response_link in response_links:\n",
    "        #print response_link\n",
    "        new_links.append(\"https://www.predictit.org\" + response_link)\n",
    "        sub_id = re.search(\"/\\d+/\", response_link).group().strip(\"/\")\n",
    "        #print id, sub_id\n",
    "        item = MarketQuestion(id, sub_id)\n",
    "        session.merge(item)\n",
    "    session.commit()\n",
    "    time.sleep(sleep_time)\n",
    "    \n",
    "contract_links = new_links + contract_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\n",
      "301\n"
     ]
    }
   ],
   "source": [
    "#len(contract_links)\n",
    "print len(contract_links) \n",
    "print len(set(contract_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_table(in_table):\n",
    "    table = etree.XML(in_table)\n",
    "    rows = iter(table)\n",
    "    headers = [col.text for col in next(rows)]\n",
    "    output = []\n",
    "    for row in rows:\n",
    "        values = [col.text for col in row]\n",
    "        output.append([values[0], values[1], values[3], values[4]])\n",
    "        \n",
    "    return output\n",
    "\n",
    "def parse_data_table(in_table):\n",
    "    table = etree.XML(in_table)\n",
    "    rows = iter(table)\n",
    "    data = {}\n",
    "    for row in rows:\n",
    "        values = [col.text for col in row]\n",
    "        data[values[0].replace(\":\", \"\")] = values[1]\n",
    "    return data\n",
    "\n",
    "count = 0\n",
    "\n",
    "while(true):\n",
    "    print \"%i'th iteration!\" % count\n",
    "    count += 1\n",
    "    for link in contract_links:\n",
    "        #print link\n",
    "\n",
    "        #link = \"https://www.predictit.org/Contract/475/Will-North-Korea-test-a-nuclear-weapon-before-the-end-of-2015#openoffers1\"\n",
    "\n",
    "        try:\n",
    "            r = requests.get(link)\n",
    "            response = TextResponse(r.url, body=r.text, encoding='utf-8')\n",
    "\n",
    "            id = re.search(\"/\\d+/\", link).group().strip(\"/\")\n",
    "            timestamp = datetime.datetime.now()\n",
    "\n",
    "            data_table = response.xpath('//div[@id=\"data1\"]').css('.table-condensed tbody')\n",
    "            data_fields = parse_data_table(data_table.extract()[0])\n",
    "            #print data_fields\n",
    "            #question_id, symbol, last_update, start_date, end_date, shares_traded, total_shares, today_volume, today_change\n",
    "            question = Question(id, \n",
    "                                data_fields[\"Symbol\"], \n",
    "                                timestamp, \n",
    "                                datetime.datetime.strptime(data_fields[\"Start Date\"], '%m/%d/%Y'), \n",
    "                                datetime.datetime.strptime(data_fields[\"End Date\"], '%m/%d/%Y'), \n",
    "                                int(data_fields[\"Shares Traded\"].replace(',', '')),\n",
    "                                int(data_fields[\"Total Shares\"].replace(',', '')),\n",
    "                                int(data_fields[\"Today's Volume\"].replace(',', '')),\n",
    "                                int(data_fields[\"Today's Change\"].replace(',', '').replace(\"NC\", \"0\").replace(\"N/A\", \"0\")))\n",
    "\n",
    "            session.add(question)\n",
    "            price_tables = response.xpath('//div[@id=\"openoffers1\"]').css('.table-condensed tbody')\n",
    "\n",
    "            yes_table = parse_table(price_tables[0].extract())\n",
    "            #no_table = parse_table(price_tables[1].extract())\n",
    "\n",
    "            #print yes_table\n",
    "\n",
    "            for row in yes_table:\n",
    "\n",
    "                if row[0]:\n",
    "                    item = BidOffer(id, timestamp, row[0], row[1], True)\n",
    "                    session.add(item)\n",
    "                if row[2]:\n",
    "                    item = BidOffer(id, timestamp, row[2], row[3], False)\n",
    "                    session.add(item)\n",
    "\n",
    "            session.commit()\n",
    "        except Exception,e: \n",
    "            print str(e)\n",
    "\n",
    "\n",
    "        time.sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_old_tables = True\n",
    "\n",
    "if drop_old_tables:\n",
    "    db.engine.execute(\"drop table if exists bids_offers\")\n",
    "    db.engine.execute(\"drop table if exists questions\")\n",
    "    db.engine.execute(\"drop table if exists market_questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_old_tables = True\n",
    "\n",
    "if drop_old_tables:\n",
    "    db.engine.execute(\"truncate table bids_offers\")\n",
    "    db.engine.execute(\"truncate table questions\")\n",
    "    db.engine.execute(\"truncate table market_questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CREATE\n",
    "    or replace\n",
    "    \n",
    "    VIEW current_bids_offers\n",
    "    AS \n",
    "    select question_id, timestamp, price, shares, buy_order from bids_offers natural join  current_questions;\n",
    "\t\t\n",
    "        \n",
    "        CREATE\n",
    "    or replace\n",
    "    \n",
    "    VIEW current_questions\n",
    "    AS  select question_id, max(timestamp) from questions group by question_id\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    select question_id, timestamp, price, shares, buy_order from bids_offers natural join  current_questions;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        CREATE\n",
    "    or replace\n",
    "    \n",
    "    VIEW current_prices_spread as\n",
    "\n",
    "select question_id, max_buy, min_sell, min_sell - max_buy as spread, shares_traded, total_shares, today_volume from\n",
    "min_sell\n",
    "natural join  max_buy\n",
    "natural join current_questions\n",
    "order by min_sell - max_buy desc\n",
    "\n",
    "\n",
    "select sum(today_volume) from current_questions\n",
    "\n",
    "\n",
    "        CREATE\n",
    "    or replace\n",
    "    \n",
    "    VIEW max_buy as select question_id, max(price) as max_buy from current_bids_offers where buy_order = 0 group by question_id, buy_order\n",
    "    \n",
    "    \n",
    "        CREATE\n",
    "    or replace view min_sell as select question_id, min(price) as min_sell from current_bids_offers where buy_order = 1 group by question_id, buy_order\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
