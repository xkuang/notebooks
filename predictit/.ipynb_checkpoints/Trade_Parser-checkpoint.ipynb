{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pybrain\n",
    "from pybrain.structure import FeedForwardNetwork\n",
    "from pybrain.structure import LinearLayer, SigmoidLayer\n",
    "from pybrain.structure import FullConnection\n",
    "from pybrain.datasets import SupervisedDataSet\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import random\n",
    "import ast\n",
    "import time\n",
    "import sqlalchemy\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy import event\n",
    "import sqlite3\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import *\n",
    "import urllib2\n",
    "import urllib\n",
    "import json\n",
    "import glob\n",
    "import pprint\n",
    "import dateutil.parser\n",
    "import pprint\n",
    "import re\n",
    "from sklearn import linear_model, datasets\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from sklearn import svm\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "import numpy\n",
    "import time\n",
    "import sqlalchemy\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy import event\n",
    "from sqlalchemy.dialects.mysql import LONGTEXT\n",
    "import sqlite3\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import *\n",
    "import urllib2\n",
    "import urllib\n",
    "import json\n",
    "import pprint\n",
    "import dateutil.parser\n",
    "import gevent\n",
    "import datetime\n",
    "import marshal\n",
    "\n",
    "import re, math, collections, itertools\n",
    "import nltk, nltk.classify.util, nltk.metrics\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import scrapy\n",
    "\n",
    "import urllib3.contrib.pyopenssl\n",
    "urllib3.contrib.pyopenssl.inject_into_urllib3()\n",
    "\n",
    "import requests\n",
    "from scrapy.http import TextResponse\n",
    "from lxml import etree\n",
    "import sys\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "little_sleep = .5\n",
    "sleep_time = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "mysql_url = \"mysql://forex:yummy4money@forex.c2ggnaqt6wye.us-west-1.rds.amazonaws.com/forex\"\n",
    "sqlite_url = 'sqlite:///database.db'\n",
    "db = create_engine(mysql_url, echo=False)\n",
    "session = sessionmaker()\n",
    "session.configure(bind=db)\n",
    "session = session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions_to_watch = [523]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_data = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pickle.dump(history, open(\"history.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76993 shares were traded!\n",
      "7 shares were traded!\n",
      "55 shares were traded!\n",
      "200 shares were traded!\n",
      "5 shares were traded!\n",
      "10 shares were traded!\n",
      "35 shares were traded!\n",
      "7 shares were traded!\n",
      "5 shares were traded!\n",
      "3 shares were traded!\n"
     ]
    }
   ],
   "source": [
    "while(true):\n",
    "    for question in questions_to_watch:\n",
    "\n",
    "        result = get_question_data(question)\n",
    "        history.append(result)\n",
    "        \n",
    "        if result:\n",
    "            data_fields, yes_table = result\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if not question_data[question]:\n",
    "            question_data[question][\"today_volume\"] = int(data_fields[\"Today's Volume\"].replace(\",\", \"\"))\n",
    "        else:\n",
    "            #print question_data[question]\n",
    "            past_today_volume = question_data[question][\"today_volume\"]\n",
    "            today_volume = int(data_fields[\"Today's Volume\"].replace(\",\", \"\"))\n",
    "\n",
    "            shares_traded = today_volume - past_today_volume\n",
    "            if shares_traded != 0:\n",
    "                print \"%i shares were traded!\" % shares_traded\n",
    "                question_data[question][\"today_volume\"] = today_volume\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 shares were traded!\n",
      "1 shares were traded!\n",
      "25 shares were traded!\n",
      "38 shares were traded!\n",
      "7 shares were traded!\n",
      "25 shares were traded!\n",
      "10 shares were traded!\n",
      "10 shares were traded!\n",
      "59 shares were traded!\n",
      "1 shares were traded!\n",
      "50 shares were traded!\n",
      "5 shares were traded!\n",
      "5 shares were traded!\n",
      "-23665 shares were traded!\n",
      "21 shares were traded!\n",
      "11 shares were traded!\n",
      "1 shares were traded!\n",
      "2 shares were traded!\n",
      "15 shares were traded!\n",
      "10 shares were traded!\n",
      "45 shares were traded!\n",
      "25 shares were traded!\n",
      "15 shares were traded!\n",
      "6 shares were traded!\n",
      "10 shares were traded!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-83fe3cdeea3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0mquestion_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"today_volume\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoday_volume\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msleep_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while(true):\n",
    "    for question in questions_to_watch:\n",
    "\n",
    "        result = get_question_data(question)\n",
    "        if result:\n",
    "            history.append(result)\n",
    "\n",
    "            process_result(question, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_result(question, result):\n",
    "    data_fields, yes_table = result\n",
    "\n",
    "    today_volume = int(data_fields[\"Today's Volume\"].replace(\",\", \"\"))\n",
    "\n",
    "    if not question_data[question]:\n",
    "        question_data[question][\"today_volume\"] = today_volume\n",
    "        question_data[question][\"yes_table\"] = yes_table\n",
    "    else:\n",
    "        #print question_data[question]\n",
    "        past_today_volume = question_data[question][\"today_volume\"]   \n",
    "        past_yes_table = question_data[question][\"yes_table\"]  \n",
    "\n",
    "        shares_traded = today_volume - past_today_volume\n",
    "        if shares_traded != 0:\n",
    "            print \"%i shares were traded!\" % shares_traded\n",
    "            question_data[question][\"today_volume\"] = today_volume\n",
    "            num_changes = 0\n",
    "            for row in yes_table:\n",
    "                if \n",
    "        \n",
    "        question_data[question][\"yes_table\"] = yes_table\n",
    "        \n",
    "    sys.stdout.flush()\n",
    "    time.sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_table(in_table):\n",
    "    table = etree.XML(in_table)\n",
    "    rows = iter(table)\n",
    "    headers = [col.text for col in next(rows)]\n",
    "    output = []\n",
    "    for row in rows:\n",
    "        values = [col.text for col in row]\n",
    "        output.append([values[0], values[1], values[3], values[4]])\n",
    "        \n",
    "    return output\n",
    "\n",
    "def parse_data_table(in_table):\n",
    "    table = etree.XML(in_table)\n",
    "    rows = iter(table)\n",
    "    data = {}\n",
    "    for row in rows:\n",
    "        values = [col.text for col in row]\n",
    "        data[values[0].replace(\":\", \"\")] = values[1]\n",
    "    return data\n",
    "\n",
    "def get_question_data(question):\n",
    "    time.sleep(little_sleep)\n",
    "    link = \"https://www.predictit.org/Contract/\" + str(523) + \"/\"\n",
    "    try:\n",
    "        #print link\n",
    "        r = requests.get(link)\n",
    "        response = TextResponse(r.url, body=r.text, encoding='utf-8')\n",
    "        \n",
    "        id = re.search(\"/\\d+/\", link).group().strip(\"/\")\n",
    "        timestamp = datetime.datetime.now()\n",
    "\n",
    "        data_table = response.xpath('//div[@id=\"data1\"]').css('.table-condensed tbody')\n",
    "        data_fields = parse_data_table(data_table.extract()[0])\n",
    "        #print data_fields\n",
    "        #question_id, symbol, last_update, start_date, end_date, shares_traded, total_shares, today_volume, today_change\n",
    "        \"\"\"question = Question(id, \n",
    "                            data_fields[\"Symbol\"], \n",
    "                            timestamp, \n",
    "                            datetime.datetime.strptime(data_fields[\"Start Date\"], '%m/%d/%Y'), \n",
    "                            datetime.datetime.strptime(data_fields[\"End Date\"], '%m/%d/%Y'), \n",
    "                            int(data_fields[\"Shares Traded\"].replace(',', '')),\n",
    "                            int(data_fields[\"Total Shares\"].replace(',', '')),\n",
    "                            int(data_fields[\"Today's Volume\"].replace(',', '')),\n",
    "                            int(data_fields[\"Today's Change\"].replace(',', '').replace(\"NC\", \"0\").replace(\"N/A\", \"0\")))\n",
    "\n",
    "        session.add(question)\"\"\"\n",
    "        price_tables = response.xpath('//div[@id=\"openoffers1\"]').css('.table-condensed tbody')\n",
    "\n",
    "        yes_table = parse_table(price_tables[0].extract())\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        for row in yes_table:\n",
    "\n",
    "            if row[0]:\n",
    "                item = BidOffer(id, timestamp, row[0], row[1], True)\n",
    "                session.add(item)\n",
    "            if row[2]:\n",
    "                item = BidOffer(id, timestamp, row[2], row[3], False)\n",
    "                session.add(item)\n",
    "\n",
    "        session.commit()\n",
    "        \"\"\"\n",
    "        return (data_fields, yes_table)\n",
    "    except Exception,e: \n",
    "        print str(e)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_old_tables = True\n",
    "\n",
    "if drop_old_tables:\n",
    "    db.engine.execute(\"drop table if exists bids_offers\")\n",
    "    db.engine.execute(\"drop table if exists questions\")\n",
    "    db.engine.execute(\"drop table if exists market_questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_old_tables = True\n",
    "\n",
    "if drop_old_tables:\n",
    "    db.engine.execute(\"truncate table bids_offers\")\n",
    "    db.engine.execute(\"truncate table questions\")\n",
    "    db.engine.execute(\"truncate table market_questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CREATE\n",
    "    or replace\n",
    "    \n",
    "    VIEW current_bids_offers\n",
    "    AS \n",
    "    select question_id, timestamp, price, shares, buy_order from bids_offers natural join  current_questions;\n",
    "\t\t\n",
    "        \n",
    "        CREATE\n",
    "    or replace\n",
    "    \n",
    "    VIEW current_questions\n",
    "    AS  select question_id, max(timestamp) from questions group by question_id\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    select question_id, timestamp, price, shares, buy_order from bids_offers natural join  current_questions;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        CREATE\n",
    "    or replace\n",
    "    \n",
    "    VIEW current_prices_spread as\n",
    "\n",
    "select question_id, max_buy, min_sell, min_sell - max_buy as spread, shares_traded, total_shares, today_volume from\n",
    "min_sell\n",
    "natural join  max_buy\n",
    "natural join current_questions\n",
    "order by min_sell - max_buy desc\n",
    "\n",
    "\n",
    "select sum(today_volume) from current_questions\n",
    "\n",
    "\n",
    "        CREATE\n",
    "    or replace\n",
    "    \n",
    "    VIEW max_buy as select question_id, max(price) as max_buy from current_bids_offers where buy_order = 0 group by question_id, buy_order\n",
    "    \n",
    "    \n",
    "        CREATE\n",
    "    or replace view min_sell as select question_id, min(price) as min_sell from current_bids_offers where buy_order = 1 group by question_id, buy_order\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
