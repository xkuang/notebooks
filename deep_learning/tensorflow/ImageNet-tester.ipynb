{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import xml\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import patches\n",
    "from random import shuffle, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imagenet Data import\n",
    "home_dir = os.path.expanduser('~') + \"/\"\n",
    "datasets_dir = home_dir + \"external_drive/\"\n",
    "imagenet_dir = datasets_dir + \"imagenet/\"\n",
    "imagenet_files_dir = imagenet_dir + \"2012_train/\"\n",
    "\n",
    "# Get list of training images\n",
    "train_filenames = []\n",
    "with open(imagenet_dir + \"2012_train_filenames.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        train_filenames.append(line.strip())    \n",
    "        \n",
    "# TURN THESE INTO TENSORFLOW VARIABLES SO THEY CAN BE DYNAMICALLY CHANGED\n",
    "\n",
    "# The width and height of the image\n",
    "image_size = 224 # Must be divisible by the pooling layers\n",
    "# Image depth\n",
    "image_depth = 3\n",
    "# The batch size\n",
    "batch_size = 128\n",
    "test_batch_size = 256\n",
    "# number of classes\n",
    "num_classes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all class names from filenames, and index them for use in one-hot labeling\n",
    "classes = set()\n",
    "for filename in train_filenames:\n",
    "    classes.add(filename.split(\"_\")[0])\n",
    "index_to_class = list(classes)\n",
    "class_to_index = {}\n",
    "for index, classname in enumerate(index_to_class):\n",
    "    class_to_index[classname] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a list of (filename, class) pairings for use as input to tensorflow pipeline\n",
    "filenames_with_classes = []\n",
    "for filename in train_filenames:\n",
    "    class_name = str(class_to_index[filename.split(\"_\")[0]])\n",
    "    filenames_with_classes.append([imagenet_files_dir+filename, class_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for f in train_filenames:\n",
    "#    if not tf.gfile.Exists(imagenet_files_dir + f):\n",
    "#        raise ValueError('Failed to find file: ' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filenames_with_classes_tensor = tf.convert_to_tensor(filenames_with_classes)\n",
    "\n",
    "# Create a queue that produces the filenames to read.\n",
    "#filename_queue = tf.train.slice_input_producer(filenames_with_classes[:10000], shuffle=True, capacity=len(filenames_with_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#QUEUE CURRENTLY ONLY HAS ONE EPOCH OF FILENAMES!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_provider(filenames_with_classes):\n",
    "    queue = tf.RandomShuffleQueue(len(filenames_with_classes), 1, tf.string)\n",
    "    enqueue_filenames = queue.enqueue_many(tf.convert_to_tensor(filenames_with_classes))\n",
    "\n",
    "    dequeue_op = queue.dequeue()\n",
    "    requeue_op = queue.enqueue(dequeue_op)\n",
    "\n",
    "    dequeue_after_requeue = tf.tuple([dequeue_op], control_inputs=[requeue_op])[0]\n",
    "    filename, class_index = tf.unpack(dequeue_after_requeue, 2)\n",
    "    return filename, class_index, enqueue_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename, class_index):\n",
    "    filename_queue = tf.FIFOQueue(10, tf.string)\n",
    "    a = filename_queue.enqueue(filename)\n",
    "    \n",
    "    reader = tf.WholeFileReader()\n",
    "    key, value = reader.read(filename_queue)\n",
    "    \n",
    "    return tf.tuple([value, class_index], control_inputs=[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/ops/image_ops.py:639: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  if width == new_width_const and height == new_height_const:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ImageSummary:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_to_queue, class_index_to_queue, enqueue_filenames = shuffle_provider(filenames_with_classes)\n",
    "\n",
    "raw_image, class_index = read_file(filename_to_queue, class_index_to_queue)\n",
    "\n",
    "# Convert from a jpeg image string to a raw image\n",
    "decoded_image = tf.image.decode_jpeg(raw_image, channels=3)\n",
    "\n",
    "# Desired sizes\n",
    "height = image_size\n",
    "width = image_size\n",
    "\n",
    "# Image processing for evaluation.\n",
    "\n",
    "# TODO - make this a crop, not a resize!!!!!!!!!!!!!!\n",
    "resized_image = tf.image.resize_images(decoded_image, width, height)\n",
    "\n",
    "# Subtract off the mean and divide by the variance of the pixels.\n",
    "float_image = tf.image.per_image_whitening(resized_image)\n",
    "\n",
    "num_preprocess_threads = 32\n",
    "# Don't need to shuffle\n",
    "\n",
    "\n",
    "x, y_ = tf.train.batch(\n",
    "  [tf.reshape(float_image, [image_size, image_size, 3]), tf.reshape(class_index, [1,])],\n",
    "  batch_size=batch_size,\n",
    "  num_threads=num_preprocess_threads,\n",
    "  capacity = 10 * batch_size)\n",
    "\n",
    "# Arrange labels into vector of 1 x batch_size (is this necessary?)\n",
    "y_ = tf.reshape(y_, [batch_size])\n",
    "#y_ = tf.cast(y_, tf.int32)\n",
    "y_ = tf.string_to_number(y_, out_type=tf.int32)\n",
    "\n",
    "# Display the training images in the visualizer.\n",
    "tf.image_summary('images', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = np.ones([batch_size, image_size, image_size, image_depth])\n",
    "input_class = np.random.rand(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 9.05332064628601\n",
      "elapsed time: 8.488260984420776\n",
      "elapsed time: 8.488198041915894\n",
      "elapsed time: 8.487354516983032\n",
      "elapsed time: 8.489539623260498\n",
      "elapsed time: 8.490085363388062\n",
      "elapsed time: 8.487428188323975\n",
      "elapsed time: 8.485820293426514\n",
      "elapsed time: 8.489726066589355\n",
      "elapsed time: 8.488215684890747\n",
      "elapsed time: 8.490323305130005\n",
      "elapsed time: 8.490659952163696\n",
      "elapsed time: 8.484283924102783\n",
      "elapsed time: 8.487655878067017\n",
      "elapsed time: 8.491753101348877\n",
      "elapsed time: 8.494855403900146\n",
      "elapsed time: 8.492705583572388\n",
      "elapsed time: 8.491931676864624\n",
      "elapsed time: 8.489259719848633\n",
      "elapsed time: 8.495267152786255\n",
      "elapsed time: 8.491401672363281\n",
      "elapsed time: 8.493325233459473\n",
      "elapsed time: 8.4912109375\n",
      "elapsed time: 8.490513324737549\n",
      "elapsed time: 8.490334272384644\n",
      "elapsed time: 8.487227201461792\n",
      "elapsed time: 8.490408897399902\n",
      "elapsed time: 8.487499475479126\n",
      "elapsed time: 8.489426851272583\n",
      "elapsed time: 8.485981941223145\n",
      "elapsed time: 8.488067388534546\n",
      "elapsed time: 8.494031429290771\n",
      "elapsed time: 8.490405559539795\n",
      "elapsed time: 8.488089084625244\n",
      "elapsed time: 8.493962526321411\n",
      "elapsed time: 8.491004228591919\n",
      "elapsed time: 8.494860410690308\n",
      "elapsed time: 8.491316795349121\n",
      "elapsed time: 8.488051891326904\n",
      "elapsed time: 8.49283480644226\n",
      "elapsed time: 8.488823413848877\n",
      "elapsed time: 8.489239692687988\n",
      "elapsed time: 8.491218328475952\n",
      "elapsed time: 8.488590717315674\n",
      "elapsed time: 8.491509914398193\n",
      "elapsed time: 8.494131088256836\n",
      "elapsed time: 8.490821361541748\n",
      "elapsed time: 8.493991374969482\n",
      "elapsed time: 8.490966558456421\n",
      "elapsed time: 8.492058753967285\n",
      "elapsed time: 8.493332862854004\n",
      "elapsed time: 8.494019508361816\n",
      "elapsed time: 8.492145776748657\n",
      "elapsed time: 8.490362882614136\n",
      "elapsed time: 8.492751121520996\n",
      "elapsed time: 8.491074085235596\n",
      "elapsed time: 8.491480588912964\n",
      "elapsed time: 8.491114854812622\n",
      "elapsed time: 8.487786531448364\n",
      "elapsed time: 8.490971803665161\n",
      "elapsed time: 8.494194746017456\n",
      "elapsed time: 8.490105152130127\n",
      "elapsed time: 8.49878716468811\n",
      "elapsed time: 8.493346214294434\n",
      "elapsed time: 8.48957872390747\n",
      "elapsed time: 8.49113917350769\n",
      "elapsed time: 8.492799043655396\n",
      "elapsed time: 8.492621421813965\n",
      "elapsed time: 8.489358186721802\n",
      "elapsed time: 8.491258382797241\n",
      "elapsed time: 8.492400407791138\n",
      "elapsed time: 8.49543833732605\n",
      "elapsed time: 8.495013952255249\n",
      "elapsed time: 8.493660926818848\n",
      "elapsed time: 8.493266820907593\n",
      "elapsed time: 8.488729476928711\n",
      "elapsed time: 8.489543676376343\n",
      "elapsed time: 8.494270086288452\n",
      "elapsed time: 8.49215292930603\n",
      "elapsed time: 8.49449872970581\n",
      "elapsed time: 8.493636131286621\n",
      "elapsed time: 8.493845462799072\n",
      "elapsed time: 8.493204832077026\n",
      "elapsed time: 8.49668836593628\n",
      "elapsed time: 8.491042852401733\n",
      "elapsed time: 8.490368843078613\n",
      "elapsed time: 8.494244813919067\n",
      "elapsed time: 8.49625825881958\n",
      "elapsed time: 8.493457078933716\n",
      "elapsed time: 8.490249872207642\n",
      "elapsed time: 8.49455714225769\n",
      "elapsed time: 8.485576391220093\n",
      "elapsed time: 8.492780447006226\n",
      "elapsed time: 8.491272926330566\n",
      "elapsed time: 8.495359897613525\n",
      "elapsed time: 8.493807077407837\n",
      "elapsed time: 8.493262529373169\n",
      "elapsed time: 8.491948366165161\n",
      "elapsed time: 8.498772144317627\n",
      "elapsed time: 8.489952325820923\n",
      "elapsed time: 8.49158263206482\n",
      "elapsed time: 8.497560739517212\n",
      "elapsed time: 8.490838289260864\n",
      "elapsed time: 8.491458177566528\n",
      "elapsed time: 8.493550300598145\n",
      "elapsed time: 8.487168788909912\n",
      "elapsed time: 8.491437435150146\n",
      "elapsed time: 8.494926452636719\n",
      "elapsed time: 8.49380087852478\n",
      "elapsed time: 8.503347158432007\n",
      "elapsed time: 8.493597269058228\n",
      "elapsed time: 8.488781213760376\n",
      "elapsed time: 8.490433692932129\n",
      "elapsed time: 8.48929476737976\n",
      "elapsed time: 8.496524810791016\n",
      "elapsed time: 8.491472959518433\n",
      "elapsed time: 8.496418952941895\n",
      "elapsed time: 8.49427056312561\n",
      "elapsed time: 8.50117015838623\n",
      "elapsed time: 8.492063999176025\n",
      "elapsed time: 8.491084575653076\n",
      "elapsed time: 8.500268459320068\n",
      "elapsed time: 8.4970383644104\n",
      "elapsed time: 8.493770837783813\n",
      "elapsed time: 8.495862483978271\n",
      "elapsed time: 8.499347448348999\n",
      "elapsed time: 8.487910985946655\n",
      "elapsed time: 8.493385076522827\n",
      "elapsed time: 8.494678974151611\n",
      "elapsed time: 8.491193771362305\n",
      "elapsed time: 8.491836071014404\n",
      "elapsed time: 8.4929518699646\n",
      "elapsed time: 8.499464273452759\n",
      "elapsed time: 8.497401237487793\n",
      "elapsed time: 8.500808477401733\n",
      "elapsed time: 8.488587379455566\n",
      "elapsed time: 8.496573686599731\n",
      "elapsed time: 8.494072198867798\n",
      "elapsed time: 8.49702525138855\n",
      "elapsed time: 8.493172645568848\n",
      "elapsed time: 8.491179466247559\n",
      "elapsed time: 8.492437601089478\n",
      "elapsed time: 8.488404273986816\n",
      "elapsed time: 8.496747732162476\n",
      "elapsed time: 8.493316173553467\n",
      "elapsed time: 8.494163513183594\n",
      "elapsed time: 8.491780042648315\n",
      "elapsed time: 8.491823434829712\n",
      "elapsed time: 8.49172306060791\n",
      "elapsed time: 8.491654396057129\n",
      "elapsed time: 8.494665622711182\n",
      "elapsed time: 8.490882396697998\n",
      "elapsed time: 8.492096662521362\n",
      "elapsed time: 8.49296236038208\n",
      "elapsed time: 8.49456524848938\n",
      "elapsed time: 8.494944334030151\n",
      "elapsed time: 8.49350905418396\n",
      "elapsed time: 8.495494604110718\n",
      "elapsed time: 8.49145770072937\n",
      "elapsed time: 8.489402055740356\n",
      "elapsed time: 8.495622873306274\n",
      "elapsed time: 8.490677118301392\n",
      "elapsed time: 8.492667198181152\n",
      "elapsed time: 8.49573564529419\n",
      "elapsed time: 8.49425721168518\n",
      "elapsed time: 8.493571758270264\n",
      "elapsed time: 8.4914870262146\n",
      "elapsed time: 8.492809772491455\n",
      "elapsed time: 8.490737676620483\n",
      "elapsed time: 8.498008728027344\n",
      "elapsed time: 8.495172262191772\n",
      "elapsed time: 8.49120569229126\n",
      "elapsed time: 8.48810625076294\n",
      "elapsed time: 8.496235609054565\n",
      "elapsed time: 8.496064901351929\n",
      "elapsed time: 8.493397235870361\n",
      "elapsed time: 8.495174407958984\n",
      "elapsed time: 8.495396137237549\n",
      "elapsed time: 8.497591257095337\n",
      "elapsed time: 8.494632244110107\n",
      "elapsed time: 8.492449283599854\n",
      "elapsed time: 8.492264032363892\n",
      "elapsed time: 8.494128704071045\n",
      "elapsed time: 8.487903356552124\n",
      "elapsed time: 8.494774103164673\n",
      "elapsed time: 8.494535446166992\n",
      "elapsed time: 8.488780975341797\n",
      "elapsed time: 8.492304801940918\n",
      "elapsed time: 8.497372388839722\n",
      "elapsed time: 8.493025541305542\n",
      "elapsed time: 8.504079818725586\n",
      "elapsed time: 8.494736909866333\n",
      "elapsed time: 8.49586796760559\n",
      "elapsed time: 8.492612361907959\n",
      "elapsed time: 8.491689205169678\n",
      "elapsed time: 8.493790864944458\n",
      "elapsed time: 8.493776798248291\n",
      "elapsed time: 8.495428323745728\n",
      "elapsed time: 8.490991353988647\n",
      "elapsed time: 8.498469352722168\n",
      "elapsed time: 8.492437601089478\n",
      "elapsed time: 8.493305921554565\n",
      "elapsed time: 8.49532151222229\n",
      "elapsed time: 8.494150876998901\n",
      "elapsed time: 8.491404294967651\n",
      "elapsed time: 8.498729705810547\n",
      "elapsed time: 8.499363899230957\n",
      "elapsed time: 8.496445178985596\n",
      "elapsed time: 8.49377179145813\n",
      "elapsed time: 8.493737936019897\n",
      "elapsed time: 8.492867231369019\n",
      "elapsed time: 8.493432998657227\n",
      "elapsed time: 8.491794109344482\n",
      "elapsed time: 8.495864152908325\n",
      "elapsed time: 8.490740060806274\n",
      "elapsed time: 8.491151094436646\n",
      "elapsed time: 8.490206956863403\n",
      "elapsed time: 8.492611408233643\n",
      "elapsed time: 8.493755340576172\n",
      "elapsed time: 8.491766452789307\n",
      "elapsed time: 8.492773294448853\n",
      "elapsed time: 8.491084337234497\n",
      "elapsed time: 8.493561267852783\n",
      "elapsed time: 8.497790098190308\n",
      "elapsed time: 8.499807119369507\n",
      "elapsed time: 8.494332313537598\n",
      "elapsed time: 8.493908166885376\n",
      "elapsed time: 8.496166944503784\n",
      "elapsed time: 8.493294715881348\n",
      "elapsed time: 8.493635177612305\n",
      "elapsed time: 8.500369548797607\n",
      "elapsed time: 8.493085861206055\n",
      "elapsed time: 8.491630792617798\n",
      "elapsed time: 8.49626636505127\n",
      "elapsed time: 8.490844964981079\n",
      "elapsed time: 8.493242502212524\n",
      "elapsed time: 8.491025447845459\n",
      "elapsed time: 8.493862628936768\n",
      "elapsed time: 8.492673873901367\n",
      "elapsed time: 8.497185707092285\n",
      "elapsed time: 8.495882034301758\n",
      "elapsed time: 8.501363754272461\n",
      "elapsed time: 8.492105722427368\n",
      "elapsed time: 8.494877099990845\n",
      "elapsed time: 8.492292881011963\n",
      "elapsed time: 8.49274468421936\n",
      "elapsed time: 8.491431713104248\n",
      "elapsed time: 8.492234468460083\n",
      "elapsed time: 8.495379447937012\n",
      "elapsed time: 8.494120836257935\n",
      "elapsed time: 8.494832277297974\n",
      "elapsed time: 8.497153759002686\n",
      "elapsed time: 8.491658687591553\n",
      "elapsed time: 8.490363597869873\n",
      "elapsed time: 8.49217176437378\n",
      "elapsed time: 8.494243860244751\n",
      "elapsed time: 8.489619731903076\n",
      "elapsed time: 8.493058681488037\n",
      "elapsed time: 8.492218255996704\n",
      "elapsed time: 8.491437196731567\n",
      "elapsed time: 8.492955684661865\n",
      "elapsed time: 8.49755334854126\n",
      "elapsed time: 8.495304107666016\n",
      "elapsed time: 8.496796131134033\n",
      "elapsed time: 8.496496200561523\n",
      "elapsed time: 8.496511936187744\n",
      "elapsed time: 8.494684219360352\n",
      "elapsed time: 8.494511365890503\n",
      "elapsed time: 8.49703574180603\n",
      "elapsed time: 8.491065263748169\n",
      "elapsed time: 8.843165159225464\n",
      "elapsed time: 8.494389533996582\n",
      "elapsed time: 9.860249996185303\n",
      "elapsed time: 8.48922610282898\n",
      "elapsed time: 8.510734796524048\n",
      "elapsed time: 8.564388036727905\n",
      "elapsed time: 8.495049238204956\n",
      "elapsed time: 8.50044560432434\n",
      "elapsed time: 8.49264645576477\n",
      "elapsed time: 8.497010946273804\n",
      "elapsed time: 8.493216514587402\n",
      "elapsed time: 8.492873191833496\n",
      "elapsed time: 8.49379014968872\n",
      "elapsed time: 8.489910364151001\n",
      "elapsed time: 8.496648073196411\n",
      "elapsed time: 8.505819320678711\n",
      "elapsed time: 8.515639305114746\n",
      "elapsed time: 8.510320663452148\n",
      "elapsed time: 8.492913961410522\n",
      "elapsed time: 8.507904767990112\n",
      "elapsed time: 8.493797063827515\n",
      "elapsed time: 8.503757953643799\n",
      "elapsed time: 8.493481874465942\n",
      "elapsed time: 8.491631269454956\n",
      "elapsed time: 8.494160652160645\n",
      "elapsed time: 8.49312686920166\n",
      "elapsed time: 8.494860410690308\n",
      "elapsed time: 8.491517305374146\n",
      "elapsed time: 8.491347551345825\n",
      "elapsed time: 8.490400552749634\n",
      "elapsed time: 8.493387699127197\n",
      "elapsed time: 8.50106930732727\n",
      "elapsed time: 8.490275859832764\n",
      "elapsed time: 8.495536088943481\n",
      "elapsed time: 8.496449947357178\n",
      "elapsed time: 8.495368003845215\n",
      "elapsed time: 8.492632389068604\n",
      "elapsed time: 8.495930433273315\n",
      "elapsed time: 8.495251417160034\n",
      "elapsed time: 8.492947101593018\n",
      "elapsed time: 8.49451494216919\n",
      "elapsed time: 8.500665664672852\n",
      "elapsed time: 8.49488115310669\n",
      "elapsed time: 8.498913049697876\n",
      "elapsed time: 8.492246150970459\n",
      "elapsed time: 8.489423513412476\n",
      "elapsed time: 8.494277238845825\n",
      "elapsed time: 8.496345281600952\n",
      "elapsed time: 8.495884656906128\n",
      "elapsed time: 8.49402117729187\n",
      "elapsed time: 8.502181768417358\n",
      "elapsed time: 8.493218660354614\n",
      "elapsed time: 8.490728855133057\n",
      "elapsed time: 8.49914836883545\n",
      "elapsed time: 8.507502317428589\n",
      "elapsed time: 8.49194049835205\n",
      "elapsed time: 8.498735427856445\n",
      "elapsed time: 8.488694667816162\n",
      "elapsed time: 8.492531538009644\n",
      "elapsed time: 8.490927934646606\n",
      "elapsed time: 8.494584560394287\n",
      "elapsed time: 8.488431930541992\n",
      "elapsed time: 8.491267919540405\n",
      "elapsed time: 8.491950750350952\n",
      "elapsed time: 8.49431300163269\n",
      "elapsed time: 8.490521430969238\n",
      "elapsed time: 8.494283437728882\n",
      "elapsed time: 8.496225595474243\n",
      "elapsed time: 8.494365215301514\n",
      "elapsed time: 8.501434803009033\n",
      "elapsed time: 8.493472337722778\n",
      "elapsed time: 8.496374607086182\n",
      "elapsed time: 8.494598150253296\n",
      "elapsed time: 8.488424062728882\n",
      "elapsed time: 8.489108324050903\n",
      "elapsed time: 8.492973327636719\n",
      "elapsed time: 8.497106075286865\n",
      "elapsed time: 8.492650508880615\n",
      "elapsed time: 8.493589401245117\n",
      "elapsed time: 8.49685001373291\n",
      "elapsed time: 8.494412422180176\n",
      "elapsed time: 8.502010822296143\n",
      "elapsed time: 8.49339246749878\n",
      "elapsed time: 8.492571115493774\n",
      "elapsed time: 8.492114543914795\n",
      "elapsed time: 8.49544072151184\n",
      "elapsed time: 8.493526220321655\n",
      "elapsed time: 8.490461587905884\n",
      "elapsed time: 8.492494821548462\n",
      "elapsed time: 8.4926016330719\n",
      "elapsed time: 8.490248680114746\n",
      "elapsed time: 8.492953777313232\n",
      "elapsed time: 8.49274754524231\n",
      "elapsed time: 8.491447687149048\n",
      "elapsed time: 8.503771543502808\n",
      "elapsed time: 8.501504898071289\n",
      "elapsed time: 8.490943431854248\n",
      "elapsed time: 8.492080926895142\n",
      "elapsed time: 8.493387937545776\n",
      "elapsed time: 8.49649691581726\n",
      "elapsed time: 8.489176988601685\n",
      "elapsed time: 8.494103193283081\n",
      "elapsed time: 8.495223760604858\n",
      "elapsed time: 8.490612506866455\n",
      "elapsed time: 8.491364002227783\n",
      "elapsed time: 8.49131441116333\n",
      "elapsed time: 8.490991115570068\n",
      "elapsed time: 8.489789485931396\n",
      "elapsed time: 8.492632627487183\n",
      "elapsed time: 8.494854927062988\n",
      "elapsed time: 8.491990804672241\n",
      "elapsed time: 8.493329524993896\n",
      "elapsed time: 8.492588996887207\n",
      "elapsed time: 8.49733018875122\n",
      "elapsed time: 8.506153345108032\n",
      "elapsed time: 8.510979890823364\n",
      "elapsed time: 8.493137121200562\n",
      "elapsed time: 8.491535663604736\n",
      "elapsed time: 8.492004871368408\n",
      "elapsed time: 8.494468927383423\n",
      "elapsed time: 8.492687463760376\n",
      "elapsed time: 8.491191625595093\n",
      "elapsed time: 8.488786458969116\n",
      "elapsed time: 8.488558292388916\n",
      "elapsed time: 8.489009618759155\n",
      "elapsed time: 8.490107774734497\n",
      "elapsed time: 8.492312908172607\n",
      "elapsed time: 8.495927572250366\n",
      "elapsed time: 8.49231767654419\n",
      "elapsed time: 8.492095232009888\n",
      "elapsed time: 8.494059562683105\n",
      "elapsed time: 8.49185061454773\n",
      "elapsed time: 8.49161171913147\n",
      "elapsed time: 8.492407083511353\n",
      "elapsed time: 8.489226579666138\n",
      "elapsed time: 8.491738557815552\n",
      "elapsed time: 8.491636276245117\n",
      "elapsed time: 8.493294477462769\n",
      "elapsed time: 8.489525556564331\n",
      "elapsed time: 8.49375295639038\n",
      "elapsed time: 8.496001720428467\n",
      "elapsed time: 8.492931604385376\n",
      "elapsed time: 8.492203950881958\n",
      "elapsed time: 8.500752925872803\n",
      "elapsed time: 8.49332046508789\n",
      "elapsed time: 8.498083114624023\n",
      "elapsed time: 8.493772983551025\n",
      "elapsed time: 8.49002194404602\n",
      "elapsed time: 8.489862203598022\n",
      "elapsed time: 8.494776725769043\n",
      "elapsed time: 8.500008344650269\n",
      "elapsed time: 8.520825862884521\n",
      "elapsed time: 8.491724491119385\n",
      "elapsed time: 8.524582147598267\n",
      "elapsed time: 8.494252920150757\n",
      "elapsed time: 8.495280265808105\n",
      "elapsed time: 8.490448713302612\n",
      "elapsed time: 8.49137282371521\n",
      "elapsed time: 8.494348526000977\n",
      "elapsed time: 8.498234510421753\n",
      "elapsed time: 8.489668130874634\n",
      "elapsed time: 8.497769594192505\n",
      "elapsed time: 8.499079942703247\n",
      "elapsed time: 8.49031662940979\n",
      "elapsed time: 8.493436098098755\n",
      "elapsed time: 8.492806434631348\n",
      "elapsed time: 8.496331214904785\n",
      "elapsed time: 8.494627714157104\n",
      "elapsed time: 8.493329286575317\n",
      "elapsed time: 8.492522239685059\n",
      "elapsed time: 8.495430707931519\n",
      "elapsed time: 8.491535663604736\n",
      "elapsed time: 8.496346950531006\n",
      "elapsed time: 8.48762321472168\n",
      "elapsed time: 8.493846893310547\n",
      "elapsed time: 8.497355222702026\n",
      "elapsed time: 8.506967782974243\n",
      "elapsed time: 8.493133544921875\n",
      "elapsed time: 8.491238594055176\n",
      "elapsed time: 8.494398832321167\n",
      "elapsed time: 8.490367650985718\n",
      "elapsed time: 8.498770952224731\n",
      "elapsed time: 8.50213623046875\n",
      "elapsed time: 8.505297422409058\n",
      "elapsed time: 8.493405818939209\n",
      "elapsed time: 8.48942232131958\n",
      "elapsed time: 8.503520250320435\n",
      "elapsed time: 8.498843669891357\n",
      "elapsed time: 8.489766597747803\n",
      "elapsed time: 8.50402045249939\n",
      "elapsed time: 8.492995977401733\n",
      "elapsed time: 8.49561357498169\n",
      "elapsed time: 8.489534616470337\n",
      "elapsed time: 8.489506721496582\n",
      "elapsed time: 8.487514019012451\n",
      "elapsed time: 8.489670753479004\n",
      "elapsed time: 8.493829011917114\n",
      "elapsed time: 8.492013931274414\n",
      "elapsed time: 8.49222707748413\n",
      "elapsed time: 8.487746477127075\n",
      "elapsed time: 8.492065668106079\n",
      "elapsed time: 8.486728429794312\n",
      "elapsed time: 8.487170934677124\n",
      "elapsed time: 8.49527645111084\n",
      "elapsed time: 8.494463682174683\n",
      "elapsed time: 8.487913370132446\n",
      "elapsed time: 8.490689992904663\n",
      "elapsed time: 8.493192672729492\n",
      "elapsed time: 8.494295597076416\n",
      "elapsed time: 8.49335789680481\n",
      "elapsed time: 8.492352485656738\n",
      "elapsed time: 8.492452144622803\n",
      "elapsed time: 8.491403818130493\n",
      "elapsed time: 8.491323471069336\n",
      "elapsed time: 8.492788791656494\n",
      "elapsed time: 8.493026494979858\n",
      "elapsed time: 8.493011713027954\n",
      "elapsed time: 8.492652893066406\n",
      "elapsed time: 8.49135136604309\n",
      "elapsed time: 8.497057914733887\n",
      "elapsed time: 8.490826845169067\n",
      "elapsed time: 8.49170708656311\n",
      "elapsed time: 8.497986316680908\n",
      "elapsed time: 8.489636659622192\n",
      "elapsed time: 8.494832992553711\n",
      "elapsed time: 8.490777254104614\n",
      "elapsed time: 8.490824937820435\n",
      "elapsed time: 8.491406202316284\n",
      "elapsed time: 8.488508462905884\n",
      "elapsed time: 8.490936040878296\n",
      "elapsed time: 8.491615533828735\n",
      "elapsed time: 8.493028402328491\n",
      "elapsed time: 8.494853973388672\n",
      "elapsed time: 8.492752313613892\n",
      "elapsed time: 8.486969709396362\n",
      "elapsed time: 8.495537281036377\n",
      "elapsed time: 8.486953735351562\n",
      "elapsed time: 8.490791320800781\n",
      "elapsed time: 8.49416208267212\n",
      "elapsed time: 8.489815473556519\n",
      "elapsed time: 8.49921703338623\n",
      "elapsed time: 8.489311933517456\n",
      "elapsed time: 8.489839792251587\n",
      "elapsed time: 8.491346836090088\n",
      "elapsed time: 8.492747783660889\n",
      "elapsed time: 8.490739107131958\n",
      "elapsed time: 8.49526596069336\n",
      "elapsed time: 8.491883039474487\n",
      "elapsed time: 8.489646911621094\n",
      "elapsed time: 8.49097228050232\n",
      "elapsed time: 8.493617296218872\n",
      "elapsed time: 8.489521741867065\n",
      "elapsed time: 8.491198301315308\n",
      "elapsed time: 8.496624231338501\n",
      "elapsed time: 8.491483211517334\n",
      "elapsed time: 8.490569353103638\n",
      "elapsed time: 8.494861125946045\n",
      "elapsed time: 8.49587368965149\n",
      "elapsed time: 8.498185634613037\n",
      "elapsed time: 8.489061832427979\n",
      "elapsed time: 8.496248245239258\n",
      "elapsed time: 8.490526914596558\n",
      "elapsed time: 8.49052381515503\n",
      "elapsed time: 8.493547201156616\n",
      "elapsed time: 8.49333143234253\n",
      "elapsed time: 8.496777057647705\n",
      "elapsed time: 8.493077754974365\n",
      "elapsed time: 8.491609573364258\n",
      "elapsed time: 8.489537000656128\n",
      "elapsed time: 8.493150472640991\n",
      "elapsed time: 8.489619731903076\n",
      "elapsed time: 8.501031875610352\n",
      "elapsed time: 8.48953127861023\n",
      "elapsed time: 8.492939710617065\n",
      "elapsed time: 8.495419263839722\n",
      "elapsed time: 8.491490602493286\n",
      "elapsed time: 8.492926359176636\n",
      "elapsed time: 8.493249416351318\n",
      "elapsed time: 8.497273445129395\n",
      "elapsed time: 8.490907907485962\n",
      "elapsed time: 8.489990472793579\n",
      "elapsed time: 8.492732763290405\n",
      "elapsed time: 8.495861053466797\n",
      "elapsed time: 8.493677139282227\n",
      "elapsed time: 8.494805812835693\n",
      "elapsed time: 8.491337537765503\n",
      "elapsed time: 8.496675491333008\n",
      "elapsed time: 8.493169069290161\n",
      "elapsed time: 8.48895263671875\n",
      "elapsed time: 8.49194598197937\n",
      "elapsed time: 8.49398422241211\n",
      "elapsed time: 8.49394154548645\n",
      "elapsed time: 8.488900661468506\n",
      "elapsed time: 8.496078968048096\n",
      "elapsed time: 8.496544599533081\n",
      "elapsed time: 8.49516487121582\n",
      "elapsed time: 8.494588136672974\n",
      "elapsed time: 8.49217176437378\n",
      "elapsed time: 8.489368200302124\n",
      "elapsed time: 8.49211835861206\n",
      "elapsed time: 8.492526054382324\n",
      "elapsed time: 8.494380950927734\n",
      "elapsed time: 8.490079164505005\n",
      "elapsed time: 8.493414402008057\n",
      "elapsed time: 8.494383573532104\n",
      "elapsed time: 8.492921590805054\n",
      "elapsed time: 8.496394157409668\n",
      "elapsed time: 8.50049114227295\n",
      "elapsed time: 8.486156225204468\n",
      "elapsed time: 8.493950605392456\n",
      "elapsed time: 8.494060754776001\n",
      "elapsed time: 8.493887662887573\n",
      "elapsed time: 8.492839813232422\n",
      "elapsed time: 8.491838932037354\n",
      "elapsed time: 8.48888111114502\n",
      "elapsed time: 8.490484476089478\n",
      "elapsed time: 8.492886781692505\n",
      "elapsed time: 8.492336750030518\n",
      "elapsed time: 8.492515802383423\n",
      "elapsed time: 8.490823984146118\n",
      "elapsed time: 8.48818325996399\n",
      "elapsed time: 8.499515056610107\n",
      "elapsed time: 8.491050720214844\n",
      "elapsed time: 8.492333173751831\n",
      "elapsed time: 8.496960639953613\n",
      "elapsed time: 8.501479625701904\n",
      "elapsed time: 8.491847038269043\n",
      "elapsed time: 8.493744134902954\n",
      "elapsed time: 8.49274468421936\n",
      "elapsed time: 8.498518228530884\n",
      "elapsed time: 8.499671697616577\n",
      "elapsed time: 8.49589490890503\n",
      "elapsed time: 8.489861965179443\n",
      "elapsed time: 8.492348670959473\n",
      "elapsed time: 8.490248680114746\n",
      "elapsed time: 8.49258542060852\n",
      "elapsed time: 8.493113994598389\n",
      "elapsed time: 8.497899293899536\n",
      "elapsed time: 8.49949026107788\n",
      "elapsed time: 8.493566036224365\n",
      "elapsed time: 8.488057613372803\n",
      "elapsed time: 8.491433143615723\n",
      "elapsed time: 8.491867780685425\n",
      "elapsed time: 8.490812063217163\n",
      "elapsed time: 8.49047589302063\n",
      "elapsed time: 8.494190216064453\n",
      "elapsed time: 8.490072011947632\n",
      "elapsed time: 8.4937162399292\n",
      "elapsed time: 8.496156215667725\n",
      "elapsed time: 8.493932723999023\n",
      "elapsed time: 8.492820262908936\n",
      "elapsed time: 8.49176287651062\n",
      "elapsed time: 8.492603540420532\n",
      "elapsed time: 8.490783214569092\n",
      "elapsed time: 8.490612983703613\n",
      "elapsed time: 8.491271495819092\n",
      "elapsed time: 8.487406730651855\n",
      "elapsed time: 8.490924596786499\n",
      "elapsed time: 8.491146564483643\n",
      "elapsed time: 8.491926431655884\n",
      "elapsed time: 8.496580123901367\n",
      "elapsed time: 8.495848417282104\n",
      "elapsed time: 8.49023151397705\n",
      "elapsed time: 8.49532699584961\n",
      "elapsed time: 8.485829591751099\n",
      "elapsed time: 8.494927644729614\n",
      "elapsed time: 8.496978282928467\n",
      "elapsed time: 8.49368691444397\n",
      "elapsed time: 8.493497610092163\n",
      "elapsed time: 8.490094184875488\n",
      "elapsed time: 8.492649793624878\n",
      "elapsed time: 8.494174718856812\n",
      "elapsed time: 8.490747928619385\n",
      "elapsed time: 8.492832660675049\n",
      "elapsed time: 8.491518020629883\n",
      "elapsed time: 8.494759798049927\n",
      "elapsed time: 8.492568254470825\n",
      "elapsed time: 8.48957633972168\n",
      "elapsed time: 8.491797924041748\n",
      "elapsed time: 8.49258041381836\n",
      "elapsed time: 8.492090463638306\n",
      "elapsed time: 8.489412784576416\n",
      "elapsed time: 8.49148416519165\n",
      "elapsed time: 8.491514921188354\n",
      "elapsed time: 8.498785257339478\n",
      "elapsed time: 8.493072986602783\n",
      "elapsed time: 8.493107557296753\n",
      "elapsed time: 8.490422487258911\n",
      "elapsed time: 8.49376893043518\n",
      "elapsed time: 8.494827508926392\n",
      "elapsed time: 8.491095304489136\n",
      "elapsed time: 8.492019176483154\n",
      "elapsed time: 8.488215446472168\n",
      "elapsed time: 8.489028930664062\n",
      "elapsed time: 8.492000341415405\n",
      "elapsed time: 8.497788906097412\n",
      "elapsed time: 8.493414640426636\n",
      "elapsed time: 8.491530179977417\n",
      "elapsed time: 8.489962577819824\n",
      "elapsed time: 8.490837574005127\n",
      "elapsed time: 8.491938352584839\n",
      "elapsed time: 8.499596357345581\n",
      "elapsed time: 8.495673179626465\n",
      "elapsed time: 8.49336051940918\n",
      "elapsed time: 8.491199254989624\n",
      "elapsed time: 8.492650032043457\n",
      "elapsed time: 8.494949340820312\n",
      "elapsed time: 8.489019870758057\n",
      "elapsed time: 8.492326021194458\n",
      "elapsed time: 8.493959903717041\n",
      "elapsed time: 8.494956731796265\n",
      "elapsed time: 8.491876363754272\n",
      "elapsed time: 8.490484714508057\n",
      "elapsed time: 8.49798321723938\n",
      "elapsed time: 8.493211030960083\n",
      "elapsed time: 8.49190092086792\n",
      "elapsed time: 8.492637634277344\n",
      "elapsed time: 8.49481463432312\n",
      "elapsed time: 8.491469621658325\n",
      "elapsed time: 8.48962950706482\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-d8e83b59072f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0miter1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m#dummy1 = sess.run([cross_entropy_mean_summary], feed_dict={learning_rate: learning_rate_value})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mdummy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0minput_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0minput_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlearning_rate_value\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mtimes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#dummy = sess.run([y_])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \"\"\"\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpartial_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 511\u001b[1;33m                            feed_dict_string)\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 564\u001b[1;33m                            target_list)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    569\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m       \u001b[0me_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_traceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#to y_conv failed\n",
    "learning_rate_value = 1\n",
    "last_time = time.time()\n",
    "times = []\n",
    "while(True):\n",
    "    for iter1 in range(10):\n",
    "        #dummy1 = sess.run([cross_entropy_mean_summary], feed_dict={learning_rate: learning_rate_value})\n",
    "        dummy = sess.run([train_step], feed_dict={x:input_image, y_:input_class, learning_rate: learning_rate_value})\n",
    "        times.append(time.time())\n",
    "    #dummy = sess.run([y_])\n",
    "    print(\"elapsed time: {}\".format(time.time() - last_time))\n",
    "    last_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  6.89700000e+03,   1.00000000e+00,   2.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00]),\n",
       " array([ 0.8467412 ,  0.87307813,  0.89941506,  0.925752  ,  0.95208893,\n",
       "         0.97842586,  1.00476279,  1.03109972,  1.05743666,  1.08377359,\n",
       "         1.11011052,  1.13644745,  1.16278439,  1.18912132,  1.21545825,\n",
       "         1.24179518,  1.26813211,  1.29446905,  1.32080598,  1.34714291,\n",
       "         1.37347984,  1.39981678,  1.42615371,  1.45249064,  1.47882757,\n",
       "         1.5051645 ,  1.53150144,  1.55783837,  1.5841753 ,  1.61051223,\n",
       "         1.63684916,  1.6631861 ,  1.68952303,  1.71585996,  1.74219689,\n",
       "         1.76853383,  1.79487076,  1.82120769,  1.84754462,  1.87388155,\n",
       "         1.90021849,  1.92655542,  1.95289235,  1.97922928,  2.00556622,\n",
       "         2.03190315,  2.05824008,  2.08457701,  2.11091394,  2.13725088,\n",
       "         2.16358781]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAECCAYAAAD9z2x7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6fb4134b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.hist([j-i for i, j in zip(times[:-1], times[1:])], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy_times = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6fb40b3e48>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6fb41ab390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.yscale('log', nonposy='clip')\n",
    "plt.plot([j-i for i, j in zip(times[:-1], times[1:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cross_entropy.pickle', 'wb') as handle:\n",
    "    pickle.dump(cross_entropy_times, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions for defining networks\n",
    "def weight_variable(shape, wd):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    weight_decay = tf.mul(tf.nn.l2_loss(initial), wd)\n",
    "    tf.add_to_collection('losses', weight_decay)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.0, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to implement image resizing!!! (and maybe also various augmentations)\n",
    "# Bring from 0, 255 to 0, 1\n",
    "# Subtract mean\n",
    "# Then, bounding boxes will need re-scaled also..\n",
    "\n",
    "# Mostly, but not completely, done. Also, image means might be slightly wrong due to BGR vs RGB ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Something like Alexnet\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Batched input\n",
    "#x = tf.placeholder(tf.float32, shape=[None, image_size, image_size, image_depth], name=\"Input_Image_Batch\") # batch size, image size, image size, image depth\n",
    "#y_ = tf.placeholder(tf.float32, shape=[None, num_classes], name=\"Input_Classes\") # batch size, num_classes\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, image_size, image_size, image_depth], name=\"Input_Image_Batch\") # batch size, image size, image size, image depth\n",
    "y_ = tf.placeholder(tf.int32, shape=[None], name=\"Class\") # batch size, num_classes\n",
    "\n",
    "\n",
    "# ALL MAX POOLING LAYERS SHOULD HAVE SIZE 3x3 and stride 2\n",
    "\n",
    "# First Convolutional Layer\n",
    "# Variables\n",
    "W_conv1 = weight_variable([11, 11, image_depth, 96], wd=0.0) # filter size, filter size, input channels (image depth), output channels\n",
    "b_conv1 = bias_variable([96])\n",
    "# Layers\n",
    "h_conv1 = tf.nn.relu(conv2d(x, W_conv1, stride=4) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Second Convolutional Layer\n",
    "# Variables\n",
    "W_conv2 = weight_variable([5, 5, 96, 256], wd=0.0)\n",
    "b_conv2 = bias_variable([256])\n",
    "# Layers\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2, stride=1) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Third Convolutional Layer\n",
    "# Variables\n",
    "W_conv3 = weight_variable([3, 3, 256, 384], wd=0.0)\n",
    "b_conv3 = bias_variable([384])\n",
    "# Layers\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3, stride=1) + b_conv3)\n",
    "\n",
    "# Fourth Convolutional Layer\n",
    "# Variables\n",
    "W_conv4 = weight_variable([3, 3, 384, 384], wd=0.0)\n",
    "b_conv4 = bias_variable([384])\n",
    "# Layers\n",
    "h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4, stride=1) + b_conv4)\n",
    "\n",
    "# Fifth Convolutional Layer\n",
    "# Variables\n",
    "W_conv5 = weight_variable([3, 3, 384, 256], wd=0.0)\n",
    "b_conv5 = bias_variable([256])\n",
    "# Layers\n",
    "h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, stride=1) + b_conv5)\n",
    "h_pool5 = max_pool_2x2(h_conv5)\n",
    "\n",
    "# Fully Connected 1\n",
    "# Weights\n",
    "W_fc1 = weight_variable([int(image_size/32) * int(image_size/32) * 256, 4096], wd=0.004)\n",
    "b_fc1 = bias_variable([4096])\n",
    "# Layers\n",
    "h_pool5_flat = tf.reshape(h_pool5, [-1, int(image_size/32) * int(image_size/32) * 256])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool5_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Fully Connected 2\n",
    "# Weights\n",
    "W_fc2 = weight_variable([4096, 4096], wd=0.004)\n",
    "b_fc2 = bias_variable([4096])\n",
    "# Layers\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "\n",
    "# Softmax\n",
    "# Weights\n",
    "W_fc3 = weight_variable([4096, num_classes], wd=0.0)\n",
    "b_fc3 = bias_variable([num_classes])\n",
    "# Layers\n",
    "softmax_linear = tf.matmul(h_fc2, W_fc3) + b_fc3\n",
    "y_conv=tf.nn.softmax(softmax_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learning rate \n",
    "learning_rate = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loss function \n",
    "#cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "#cross_entropy = -tf.reduce_sum(y_*tf.log(tf.clip_by_value(y_conv,1e-10,1.0))) # this fix was needed for some reason..\n",
    "\n",
    "# NEED TO ADD WEIGHT DECAY TO THIS LOSS FUNCTION\n",
    "\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "      softmax_linear, tf.to_int64(y_), name='cross_entropy_per_example')\n",
    "cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy_thingy')\n",
    "\n",
    "\n",
    "\n",
    "# Optimization Algorithm\n",
    "#train_step = tf.train.MomentumOptimizer(learning_rate, .9).minimize(cross_entropy)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy_mean)\n",
    "#train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "# Accuracy function\n",
    "#correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "#accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "correct_prediction = tf.nn.in_top_k(y_conv, y_, 1)\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_prediction, tf.int32)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make summary of cross entropy loss\n",
    "tf.scalar_summary(\"cross entropy\", cross_entropy_mean)\n",
    "\n",
    "# Make a summary of training accuracy\n",
    "tf.scalar_summary(\"accuracy\", accuracy)\n",
    "\n",
    "# Learning rate summary\n",
    "tf.scalar_summary(\"learning rate\", learning_rate)\n",
    "\n",
    "# Make a bunch of histogram summaries\n",
    "tf.histogram_summary(\"image inputs\", x)\n",
    "tf.histogram_summary(\"class inputs\", y_)\n",
    "tf.histogram_summary(\"conv1_weights\", W_conv1)\n",
    "tf.histogram_summary(\"conv2_weights\", W_conv2)\n",
    "tf.histogram_summary(\"conv3_weights\", W_conv3)\n",
    "tf.histogram_summary(\"conv4_weights\", W_conv4)\n",
    "tf.histogram_summary(\"conv5_weights\", W_conv5)\n",
    "tf.histogram_summary(\"conv1_biases\", b_conv1)\n",
    "tf.histogram_summary(\"conv2_biases\", b_conv2)\n",
    "tf.histogram_summary(\"conv3_biases\", b_conv3)\n",
    "tf.histogram_summary(\"conv4_biases\", b_conv4)\n",
    "tf.histogram_summary(\"conv5_biases\", b_conv5)\n",
    "tf.histogram_summary(\"fc1_weights\", W_fc1)\n",
    "tf.histogram_summary(\"fc1_biases\", b_fc1)\n",
    "tf.histogram_summary(\"fc2_weights\", W_fc2)\n",
    "tf.histogram_summary(\"fc2_biases\", b_fc2)\n",
    "tf.histogram_summary(\"conv1_outputs\", h_conv1)\n",
    "tf.histogram_summary(\"conv2_outputs\", h_conv2)\n",
    "tf.histogram_summary(\"conv3_outputs\", h_conv3)\n",
    "tf.histogram_summary(\"conv4_outputs\", h_conv4)\n",
    "tf.histogram_summary(\"conv5_outputs\", h_conv5)\n",
    "tf.histogram_summary(\"fc1_outputs\", h_fc1)\n",
    "tf.histogram_summary(\"fc2_outputs\", h_fc2)\n",
    "tf.histogram_summary(\"pool5_outputs\", h_pool5)\n",
    "tf.histogram_summary(\"final_predictions\", y_conv)\n",
    "\n",
    "# Merge all the summaries and write them out to /tmp/mnist_logs\n",
    "merged = tf.merge_all_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_step.run(feed_dict={learning_rate: learning_rate_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fix log directory name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Thread(Thread-3, started daemon 140117833848576)>,\n",
       " <Thread(Thread-4, started daemon 140117825455872)>,\n",
       " <Thread(Thread-5, started daemon 140117817063168)>,\n",
       " <Thread(Thread-6, started daemon 140117808670464)>,\n",
       " <Thread(Thread-7, started daemon 140117142374144)>,\n",
       " <Thread(Thread-8, started daemon 140117118297856)>,\n",
       " <Thread(Thread-9, started daemon 140117109905152)>,\n",
       " <Thread(Thread-10, started daemon 140117101512448)>,\n",
       " <Thread(Thread-11, started daemon 140117085267712)>,\n",
       " <Thread(Thread-12, started daemon 140117076875008)>,\n",
       " <Thread(Thread-13, started daemon 140116530030336)>,\n",
       " <Thread(Thread-14, started daemon 140116521637632)>,\n",
       " <Thread(Thread-15, started daemon 140116513244928)>,\n",
       " <Thread(Thread-16, started daemon 140116504852224)>,\n",
       " <Thread(Thread-17, started daemon 140116496459520)>,\n",
       " <Thread(Thread-18, started daemon 140116488066816)>,\n",
       " <Thread(Thread-19, started daemon 140116479674112)>,\n",
       " <Thread(Thread-20, started daemon 140115322074880)>,\n",
       " <Thread(Thread-21, started daemon 140115313682176)>,\n",
       " <Thread(Thread-22, started daemon 140115305289472)>,\n",
       " <Thread(Thread-23, started daemon 140115296896768)>,\n",
       " <Thread(Thread-24, started daemon 140115288504064)>,\n",
       " <Thread(Thread-25, started daemon 140115280111360)>,\n",
       " <Thread(Thread-26, started daemon 140115271718656)>,\n",
       " <Thread(Thread-27, started daemon 140114718095104)>,\n",
       " <Thread(Thread-28, started daemon 140114709702400)>,\n",
       " <Thread(Thread-29, started daemon 140114701309696)>,\n",
       " <Thread(Thread-30, started daemon 140114692916992)>,\n",
       " <Thread(Thread-31, started daemon 140114684524288)>,\n",
       " <Thread(Thread-32, started daemon 140114676131584)>,\n",
       " <Thread(Thread-33, started daemon 140114667738880)>,\n",
       " <Thread(Thread-34, started daemon 140114181224192)>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([enqueue_filenames])\n",
    "tf.train.start_queue_runners(sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "save_name = \"imagenet_11\"\n",
    "writer = tf.train.SummaryWriter(home_dir + \"projects/deep_learning/tensorflow/tmp/alexnet_logs/\"+save_name, sess.graph_def, flush_secs=10)\n",
    "#saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "last_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy_mean_summary = tf.convert_to_tensor(cross_entropy_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_entropy_mean at step 1400: 6.92012\n",
      "elapsed time: 28.149460792541504\n",
      "cross_entropy_mean at step 1420: 6.90445\n",
      "elapsed time: 20.613927841186523\n",
      "cross_entropy_mean at step 1440: 6.9168\n",
      "elapsed time: 21.103481769561768\n",
      "cross_entropy_mean at step 1460: 6.90054\n",
      "elapsed time: 32.108006715774536\n",
      "cross_entropy_mean at step 1480: 6.90433\n",
      "elapsed time: 50.92725419998169\n",
      "cross_entropy_mean at step 1500: 6.90852\n",
      "elapsed time: 60.56604051589966\n",
      "cross_entropy_mean at step 1520: 6.91409\n",
      "elapsed time: 82.34089994430542\n",
      "cross_entropy_mean at step 1540: 6.90775\n",
      "elapsed time: 25.701226711273193\n",
      "cross_entropy_mean at step 1560: 6.90107\n",
      "elapsed time: 131.3600254058838\n",
      "cross_entropy_mean at step 1580: 6.90432\n",
      "elapsed time: 86.55791425704956\n",
      "cross_entropy_mean at step 1600: 6.90799\n",
      "elapsed time: 93.08800482749939\n",
      "cross_entropy_mean at step 1620: 6.90332\n",
      "elapsed time: 100.36446499824524\n",
      "cross_entropy_mean at step 1640: 6.91019\n",
      "elapsed time: 116.34411191940308\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-30ca450fa908>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mlast_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtrain_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlearning_rate_value\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m     \"\"\"\n\u001b[1;32m-> 1394\u001b[1;33m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[1;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3222\u001b[0m                        \u001b[1;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3223\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3224\u001b[1;33m   \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \"\"\"\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpartial_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 511\u001b[1;33m                            feed_dict_string)\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 564\u001b[1;33m                            target_list)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    569\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m       \u001b[0me_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_traceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/venv/standard/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate_value = 1\n",
    "\n",
    "while(True):\n",
    "    i += 1\n",
    "    if i%20 == 0:\n",
    "        # Summary ops take about 2.5 seconds to run\n",
    "        summary, cross_entropy_mean = sess.run([merged, cross_entropy_mean_summary], \n",
    "                    feed_dict={learning_rate: learning_rate_value})\n",
    "        writer.add_summary(summary, i)\n",
    "        print(\"cross_entropy_mean at step %s: %s\" % (i, cross_entropy_mean))\n",
    "        print(\"elapsed time: {}\".format(time.time() - last_time))\n",
    "        last_time = time.time()\n",
    "    else:\n",
    "        train_step.run(feed_dict={learning_rate: learning_rate_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save weights to file\n",
    "# Could name with \"i\", the number of iterations progressed\n",
    "save_number = 1\n",
    "save_path = saver.save(sess, \"tmp/checkpoints/{save_name}_{save_number}.ckpt\".format(save_name=save_name, save_number=save_number))\n",
    "print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Restore weights from file\n",
    "#saver.restore(sess, \"/tmp/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODOS\n",
    "# Weight decay, batch normalization, bigger network, different filter sizes, inception filters\n",
    "# sgd with momentum seems standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions to load dataset\n",
    "\n",
    "def crop_resize_image(image, desired_dimension):\n",
    "    width, height, depth = image.shape\n",
    "    if width >= height:\n",
    "        cropped_image = image[int(width / 2) - int(height/2):int(width / 2) + int(height/2),:,:]\n",
    "    else:\n",
    "        cropped_image = image[:,int(height / 2) - int(width/2):int(height / 2) + int(width/2),:]\n",
    "    return cv2.resize(cropped_image, (desired_dimension, desired_dimension))\n",
    "\n",
    "# Returns a [height, width, depth] image in RGB pixel order\n",
    "def read_jpeg(filename):\n",
    "    image = cv2.imread(imagenet_dir + \"2012_train/{}\".format(filename))\n",
    "    if image is None:\n",
    "        print(\"Failed to read image! This is probably bad\")\n",
    "    # Convert BGR to RGB. \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Subtract image means from all of imagenet. I think these are RGB, but might be BGR.....\n",
    "    image = image - np.array([104, 116, 122])\n",
    "    image = image / 255.0\n",
    "    return  image\n",
    "\n",
    "# Plots an image from either filename or numpy array. \n",
    "def show_image(image):\n",
    "    if isinstance(image, str):\n",
    "        image = read_jpeg(image)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, aspect='equal')\n",
    "    ax.imshow(image)\n",
    "\n",
    "image_index = 0\n",
    "# Gets a batch of images from a given list of filenames\n",
    "def get_batch(filenames, num_images, img_size, num_classes):\n",
    "    global image_index\n",
    "    #shuffle(filenames)\n",
    "    images = []\n",
    "    classes = []\n",
    "    if image_index > len(filenames) - 2 * num_images:\n",
    "        print(\"Finished epoch, shuffling filenames!\")\n",
    "        shuffle(filenames)\n",
    "        image_index = 0\n",
    "    while len(images) < num_images:\n",
    "        filename = filenames[image_index]\n",
    "        image = read_jpeg(filename)\n",
    "        image = crop_resize_image(image, img_size)\n",
    "        images.append(image)\n",
    "        classes.append(class_to_index[filename.split(\"_\")[0]])\n",
    "        image_index += 1\n",
    "    return np.array(images), dense_to_one_hot(np.array(classes), num_classes)\n",
    "\n",
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "    \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "def one_hot_to_class(one_hot):\n",
    "    for key, value in enumerate(one_hot):\n",
    "        if value > 0:\n",
    "            return indexes_to_classes[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
