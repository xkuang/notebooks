{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pybrain\n",
    "from pybrain.structure import FeedForwardNetwork\n",
    "from pybrain.structure import LinearLayer, SigmoidLayer\n",
    "from pybrain.structure import FullConnection\n",
    "from pybrain.datasets import SupervisedDataSet\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import random\n",
    "import ast\n",
    "import time\n",
    "import sqlalchemy\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy import event\n",
    "import sqlite3\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import *\n",
    "import urllib2\n",
    "import urllib\n",
    "import json\n",
    "import glob\n",
    "import pprint\n",
    "import dateutil.parser\n",
    "import pprint\n",
    "import re\n",
    "from sklearn import linear_model, datasets\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from sklearn import svm\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "import numpy\n",
    "import time\n",
    "import sqlalchemy\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy import event\n",
    "from sqlalchemy.dialects.mysql import LONGTEXT\n",
    "import sqlite3\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import *\n",
    "import urllib2\n",
    "import urllib\n",
    "import json\n",
    "import pprint\n",
    "import dateutil.parser\n",
    "import gevent\n",
    "import datetime\n",
    "import marshal\n",
    "\n",
    "import re, math, collections, itertools\n",
    "import nltk, nltk.classify.util, nltk.metrics\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division  # Python 2 users only\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "does it even matter if the computer understands the meaning of a word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw = u\"\"\"Once upon a time, there were three little pigs who went off to build their houses.\n",
    "The first little pig built his house of straw, which was not very strong.\n",
    "One day, the big bad wolf came and said, “Little pig, little pig, let me come in.”\n",
    "“Not by the hair of my chinny chin chin,” said the first little pig.\n",
    "“Then I’ll huff and I’ll puff, and I’ll blow your house down.”\n",
    "And he did. And he got the little pig and ate him all up.\n",
    "The second little pig built his house of sticks, which were not very strong.\n",
    "One day, the big bad wolf came and said, “Little pig, little pig, let me come in.”\n",
    "“Not by the hair of my chinny chin chin,” said the second little pig.\n",
    "“Then I’ll huff and I’ll puff and I’ll blow your house down.”\n",
    "And he did. And he got the little pig and ate him all up.\n",
    "The third little pig built his house of bricks, which were very strong.\n",
    "One day, the big bad wolf came and said, “Little pig, little pig, let me come in.”\n",
    "“Not by the hair of my chinny chin chin,” said the third little pig.\n",
    "“Then I’ll huff and I’ll puff and I’ll blow your house down.”\n",
    "But no matter how much the wolf huffed and puffed, the house did not blow down.\n",
    "So the big bad wolf said, “I’ll come down the chimney and eat you all up.”\n",
    "But when the wolf came down the chimney, he fell into a pot of boiling water and boiled all up.\n",
    "And the third little pig lived happily ever after in his house of bricks.\n",
    "The end.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = word_tokenize(raw)\n",
    "text = nltk.Text(tokens)\n",
    "tags = nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def ie_preprocess(document):\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parts = ie_preprocess(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Once upon a time, there were three little pigs who went off to build their houses.',\n",
       " u'The first little pig built his house of straw, which was not very strong.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('ROOT', [Tree('S', [Tree('INTJ', [Tree('UH', ['Hello'])]), Tree(',', [',']), Tree('NP', [Tree('PRP$', ['My']), Tree('NN', ['name'])]), Tree('VP', [Tree('VBZ', ['is']), Tree('ADJP', [Tree('JJ', ['Melroy'])])]), Tree('.', ['.'])])])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('ROOT', [Tree('S', [Tree('ADVP', [Tree('RB', ['Once']), Tree('PP', [Tree('IN', ['upon']), Tree('NP', [Tree('DT', ['a']), Tree('NN', ['time'])])])]), Tree(',', [',']), Tree('NP', [Tree('EX', ['there'])]), Tree('VP', [Tree('VBD', ['were']), Tree('NP', [Tree('NP', [Tree('CD', ['three']), Tree('JJ', ['little']), Tree('NNS', ['pigs'])]), Tree('SBAR', [Tree('WHNP', [Tree('WP', ['who'])]), Tree('S', [Tree('VP', [Tree('VBD', ['went']), Tree('PRT', [Tree('RP', ['off'])]), Tree('S', [Tree('VP', [Tree('TO', ['to']), Tree('VP', [Tree('VB', ['build']), Tree('NP', [Tree('PRP$', ['their']), Tree('NNS', ['houses'])])])])])])])])])]), Tree('.', ['.'])])]), Tree('ROOT', [Tree('S', [Tree('NP', [Tree('DT', ['The']), Tree('JJ', ['first']), Tree('JJ', ['little']), Tree('NN', ['pig'])]), Tree('VP', [Tree('VBD', ['built']), Tree('NP', [Tree('NP', [Tree('PRP$', ['his']), Tree('NN', ['house'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('NP', [Tree('NN', ['straw'])]), Tree(',', [',']), Tree('SBAR', [Tree('WHNP', [Tree('WDT', ['which'])]), Tree('S', [Tree('VP', [Tree('VBD', ['was']), Tree('RB', ['not']), Tree('ADJP', [Tree('RB', ['very']), Tree('JJ', ['strong'])])])])])])])])]), Tree('.', ['.'])])])]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nltk.parse import stanford\n",
    "os.environ['STANFORD_PARSER'] = '/home/ubuntu/projects/sat/stanford_parser'\n",
    "os.environ['STANFORD_MODELS'] = '/home/ubuntu/projects/sat/stanford_parser'\n",
    "\n",
    "parser = stanford.StanfordParser(model_path=\"/home/ubuntu/projects/sat/stanford_parser/englishPCFG.ser.gz\")\n",
    "#parsed = parser.raw_parse_sents((\"Once upon a time, there were three little pigs who went off to build their houses.\", \"The first little pig built his house of straw, which was not very strong.\"))\n",
    "parsed = parser.raw_parse_sents(sentences[:2])\n",
    "print parsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
